{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eirik\\Desktop\\UIO\\FYSSTK\\Project3_FYS_STK4155\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Eirik\\Desktop\\UIO\\FYSSTK\\Project3_FYS_STK4155\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Handling paths for importing code\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from Code.utilities import MSELoss_method, cross_entropy_loss_method, predict, accuracy_func_method\n",
    "from Code.descent_methods import SGD_adam, SGD\n",
    "from Code.data_handling import load_MNIST_8, load_MNIST_28, append_run_to_file, load_run_from_file\n",
    "from Code.softmax_regression import softmax_beta_init, softmax_model, softmax\n",
    "from Code.convolutional import _beta_init_conv, convolutional_model_method\n",
    "from Code.plot import *\n",
    "\n",
    "from jax import jit, nn, grad\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the default font size for text elements (e.g., titles, labels)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 16\n",
    "mpl.rcParams[\"axes.labelsize\"] = 14\n",
    "mpl.rcParams[\"axes.titlesize\"] = 16\n",
    "mpl.rcParams['legend.fontsize'] = 14\n",
    "mpl.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['xtick.labelsize']=12\n",
    "plt.rcParams['ytick.labelsize']=12\n",
    "\n",
    "# Set filename start. Create the folder if gone\n",
    "filepath_location = \"Figures/b/\"\n",
    "if not os.path.exists(filepath_location):\n",
    "    os.makedirs(filepath_location[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_train_set(X_train, y_train, X_test, y_test):\n",
    "    return X_train[:2_000], y_train[:2_000], X_test[:400], y_test[:400]\n",
    "\n",
    "#,:,:,jnp.newaxis\n",
    "\n",
    "# download MNIST dataset\n",
    "X_train, y_train, X_test, y_test = load_MNIST_28(flatten_images=False)\n",
    "X_train, y_train, X_test, y_test = cut_train_set(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# X_train, y_train, X_test, y_test = load_MNIST_8(flatten_images=False)\n",
    "\n",
    "\n",
    "\n",
    "# Display some images\n",
    "# plot_some_imgs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv0', 'conv1', 'conv2', 'conv3', 'W1', 'b1', 'W2', 'b2', 'W3', 'b3', 'W4', 'b4'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "\n",
    "beta0 = _beta_init_conv((X_train.shape[1], X_train.shape[2]), [3, 4, 5, 8], [5, 5, 5])\n",
    "beta0.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv0', 'conv1', 'conv2', 'W1', 'b1', 'W2', 'b2', 'W3', 'b3', 'W4', 'b4'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def single_run(X_train, X_test, y_train, y_test, \n",
    "               window_size_list=[3, 4],\n",
    "               hidden_layer_list=[100, 100, 100],\n",
    "               lr=0.01, lam=0.00001, epochs=300, batch_size=32, plot_or_not=False, \n",
    "               loss_func_and_name=(cross_entropy_loss_method, \"CE\"), #(MSELoss_method, \"MSE\")\n",
    "               test_func_and_name=(MSELoss_method, \"CE\"), \n",
    "               result_filepath=None, store_params=False, intermediate_epochs=None):    \n",
    "    \"\"\"\n",
    "    Performs a training with the given parameters\n",
    "\n",
    "    Returns result, including the final accuracy scores\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise beta and create the model\n",
    "    beta0 = _beta_init_conv((X_train.shape[1], X_train.shape[2]), window_size_list, hidden_layer_list=hidden_layer_list)\n",
    "    print(beta0.keys())\n",
    "    model = jit(convolutional_model_method(len(window_size_list)))\n",
    "\n",
    "    # Create gradient from loss function\n",
    "    loss_func = jit(loss_func_and_name[0](model=model, lam=lam))\n",
    "    loss_grad = jit(grad(loss_func))\n",
    "    accuracy_func = jit(accuracy_func_method(model))\n",
    "\n",
    "    # (usually MSE) loss function for evaluation\n",
    "    if plot_or_not:\n",
    "        test_func = jit(test_func_and_name[0])\n",
    "        test_func = loss_func\n",
    "    else:\n",
    "        test_func = None\n",
    "\n",
    "    # Perform training. We use adam, add the test index\n",
    "    result = SGD_adam(X_train, y_train, X_test, y_test, \n",
    "                      grad_method=loss_grad,beta0=beta0, \n",
    "                      n_epochs=epochs, batch_size=batch_size,\n",
    "                      test_loss_func= test_func, lr=lr, \n",
    "                      intermediate_epochs=intermediate_epochs)\n",
    "\n",
    "    # Plot if wanted ...\n",
    "    if plot_or_not:\n",
    "        plot_test_results(result[\"test_loss_list\"], result[\"train_loss_list\"], ylabel=\"CE\")\n",
    "\n",
    "    # Add accuracy scores\n",
    "    result[\"test_accuracy\"]  = float(accuracy_func(result[\"beta_final\"], X_test, y_test))\n",
    "    result[\"train_accuracy\"] = float(accuracy_func(result[\"beta_final\"], X_train, y_train))\n",
    "    # Also store the model for potential later use\n",
    "    result[\"model\"] = model\n",
    "\n",
    "    # Store the result to given file\n",
    "    if result_filepath:\n",
    "\n",
    "        _dict_to_store =  { \"lr\"                : lr, \n",
    "                            \"lam\"               : lam,\n",
    "                            \"batch_size\"        : batch_size,\n",
    "                            \"train_num\"         : y_train.shape[0],\n",
    "                            \"test_num\"          : y_test.shape[0],\n",
    "                            \"loss_function\"     : loss_func_and_name[1],                            \n",
    "                            \"window_size_list\" : f\"{window_size_list}\",\n",
    "                          }\n",
    "        if store_params:\n",
    "            _dict_to_store[\"beta_final\"] = {key: value.tolist() for key, value in result[\"beta_final\"].items()}\n",
    "\n",
    "        # Possibility of storing run with fewer epochs\n",
    "        if intermediate_epochs is not None:\n",
    "            for ie, be in zip(intermediate_epochs, result[\"beta_intermediate\"]):\n",
    "                _dict_to_store = {\"test_accuracy\"     : float(accuracy_func(be, X_test, y_test)), \n",
    "                                  \"train_accuracy\"    : float(accuracy_func(be, X_train, y_train)),\n",
    "                                  \"epochs\"            : ie} | _dict_to_store\n",
    "\n",
    "                append_run_to_file(result_filepath, _dict_to_store)\n",
    "\n",
    "        _dict_to_store = {\"test_accuracy\"     : result[\"test_accuracy\"], \n",
    "                          \"train_accuracy\"    : result[\"train_accuracy\"],\n",
    "                          \"epochs\"            : epochs} | _dict_to_store\n",
    "        append_run_to_file(result_filepath, _dict_to_store)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "## A demonstration\n",
    "epochs = 100\n",
    "batch_size = 1024 #4096 2048 # 128 # 1024\n",
    "lr = 0.02 # 0.01\n",
    "lam = 0.00001\n",
    "\n",
    "result = single_run(X_train, X_test, y_train, y_test, \n",
    "                    lr=lr, lam=lam, window_size_list=[3, 9, 15], hidden_layer_list=[200, 200, 100],\n",
    "                    epochs=epochs, batch_size=batch_size, \n",
    "                    plot_or_not=True, result_filepath=\"test.json\")\n",
    "\n",
    "print(\"test: \", result[\"test_accuracy\"])\n",
    "print(\"train: \", result[\"train_accuracy\"])\n",
    "\n",
    "print(\"CE test: \", result[\"test_loss_list\"][-1])\n",
    "print(\"CE train: \", result[\"train_loss_list\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv0', 'conv1', 'W1', 'b1', 'W2', 'b2', 'W3', 'b3', 'W4', 'b4'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.9150000214576721\n",
      "train:  0.9764999747276306\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'test_loss_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Eirik\\Desktop\\UIO\\FYSSTK\\Project3_FYS_STK4155\\Runs\\c_convolutional.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eirik/Desktop/UIO/FYSSTK/Project3_FYS_STK4155/Runs/c_convolutional.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest: \u001b[39m\u001b[39m\"\u001b[39m, result[\u001b[39m\"\u001b[39m\u001b[39mtest_accuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eirik/Desktop/UIO/FYSSTK/Project3_FYS_STK4155/Runs/c_convolutional.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain: \u001b[39m\u001b[39m\"\u001b[39m, result[\u001b[39m\"\u001b[39m\u001b[39mtrain_accuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Eirik/Desktop/UIO/FYSSTK/Project3_FYS_STK4155/Runs/c_convolutional.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCE test: \u001b[39m\u001b[39m\"\u001b[39m, result[\u001b[39m\"\u001b[39;49m\u001b[39mtest_loss_list\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eirik/Desktop/UIO/FYSSTK/Project3_FYS_STK4155/Runs/c_convolutional.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCE train: \u001b[39m\u001b[39m\"\u001b[39m, result[\u001b[39m\"\u001b[39m\u001b[39mtrain_loss_list\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'test_loss_list'"
     ]
    }
   ],
   "source": [
    "## A demonstration\n",
    "epochs = 50\n",
    "batch_size = 128 #4096 2048 # 128 # 1024\n",
    "lr = 0.02 # 0.01\n",
    "lam = 0.00001\n",
    "\n",
    "result = single_run(X_train[0:15000], X_test[0:3000], y_train[0:15000], y_test[0:3000], \n",
    "                    lr=lr, lam=lam, \n",
    "                    epochs=epochs, batch_size=batch_size, \n",
    "                    plot_or_not=False, result_filepath=\"test.json\")\n",
    "\n",
    "print(\"test: \", result[\"test_accuracy\"])\n",
    "print(\"train: \", result[\"train_accuracy\"])\n",
    "\n",
    "print(\"CE test: \", result[\"test_loss_list\"][-1])\n",
    "print(\"CE train: \", result[\"train_loss_list\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
